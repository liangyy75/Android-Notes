- 操作系统概述
    - **基本特征**: 并发(并行) 共享(互斥共享和同时共享) 虚拟(时分复用技术和空分复用技术) 异步(异步)
    - **基本功能**: 进程 内存 设备 文件
    - 系统调用: 进程控制 进程通信 文件管理 设备管理 信息维护 安全
    - 用户态 内核态
    - 宏内核 微内核 Linux内核
    - 中断分类: 系统调用(陷入) 异常 外围设备的中断(外中断)
- 进程管理
    - **进程 线程**: 资源 调度 开销 通信 [进程的切换与系统的一般执行过程](https://www.cnblogs.com/huyufeng/p/5400639.html)
    - 进程状态: new(开始) ready(就绪) running(运行) waiting(阻塞) terminated(终止)
    - 线程状态(Java): new(开始) runnable(可执行start/yield) running(执行) waiting(主动等待wait/join与等待被唤醒notify/notifyAll/run执行完) time-waiting(主动睡眠sleep(seconds)/wait(seconds)/join(seconds)) blocked(阻塞synchronized/lock) dead(死亡状态)
    - 进程调度:
        - 批处理系统: 先到先服务(FCFS) 最短作业优先(SJF) 最短剩余时间优先(SRTF) [C++实现操作系统调度算法(FSFS，SJF，RR，多级反馈队列算法)](https://www.cnblogs.com/yangquanhui/p/4937485.html)
        - 交互式系统:
            - 时间片轮转(RR)
            - 优先级调度[优先级调度算法](https://blog.csdn.net/weixin_40962955/article/details/80072769)
                - 优先级相同的FCFS，优先级不同的按优先级；每执行一次优先级下降，每等待一次优先级上升。
            - 多级反馈队列([多级反馈队列调度算法(附Python3实现代码)](https://blog.csdn.net/qq_33414271/article/details/80012172))
                - n个队列，都命名为Qi(1<i<n)，每个队列都有一个时间片Ti，且Ti总小于Ti+1，方便后面大任务执行完。任务进入Qi后，执行了Ti后如果还没完成就降低优先级进入Qi+1，然后Qi中继续处理下一个任务，即FCFS，而最低优先级的是时间片轮转调度。在Qi中执行了Ta时，如果有Qj(j<i)中有新任务到达，那么中断Qi的任务，先将Qj处理，回到Qi时，继续之前的状态，即继续Ti-Ta后，切换时间片与将任务降级。
        - 实时系统: 硬实时 软实时
    - 进程同步: 
        - 临界区 临界资源
        - **同步 互斥**: 平等竞争 不可独占 互斥使用 有限等待
        - 信号量 P(down) V(up)
        - 互斥的加锁实现
        - 管程
    - 经典同步问题: 生产者-消费者问题 读者-写者问题 哲学家进餐问题
    - 线程同步: 互斥量Synchronized/Lock 信号量Semphare 事件(信号)，Wait/Notify
    - **同步 异步 阻塞 非阻塞**
    - 进程通信: FIFO 管道 信号量 消息队列 共享存储 socket套接字
    - 父子进程: 执行时间(创建子时父进程仍可执行，创建后两者并发) 内存(读时共享写时复制) 孤儿进程(父进程先执行完，被init进程托管与负责资源回收) 僵尸进程(子进程先执行完，父进程需要记得回收子进程资源)
    - 父子线程: Java中不存在实质上的父子关系，没有方法可以获取一个线程的父线程，也没有方法可以获取一个线程所有的子线程。对Java中的线程，父线程的概念，只是一种逻辑称呼，创建线程的当前线程就是新线程的父线程，新线程的一些资源来自于这个父线程。在init方法中，对于所谓父线程的处理逻辑，换一个说法就是借助于当前正在运行的线程，对新创建线程进行一些必要的赋值与初始化。
- 死锁
    - 必要条件: 互斥使用 占有与等待 不可抢占 环路等待
    - 处理方法: 鸵鸟策略 死锁检测与死锁恢复 死锁预防 死锁避免
    - 死锁检测: 每种资源单个的死锁检测(资源分配图 环) 每种资源多个的死锁检测(总资源向量 可用资源向量 进程已有资源矩阵 进程仍需资源总量)[模拟银行家算法，模拟实现动态资源分配以及随机分配算法](https://blog.csdn.net/tingke_/article/details/80957981) [银行家算法解题思路](https://blog.csdn.net/qq_38251430/article/details/79139245)
    - 死锁恢复: 杀死进程 允许抢占 进程回滚
    - 死锁预防: 破坏互斥条件 破坏占有与等待条件 破坏不可抢占条件 破坏环路等待条件
    - **死锁避免**: 安全状态 资源分配图算法/每种资源单个的银行家算法 每种资源多个的银行家算法
- 内存管理
    - 虚拟内存的目的: 让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存 每个进程都有自己独立的地址空间，都从0开始，便于分配
    - 内存的局部性: 时间局部性(由于循环指令) 空间局部性(指令一般顺序存放，以组和表的形式)
    - 内存管理的形式: 分页 分段 段页式
    - 分页: 页面 页框 页表 页表项 快表(TLB) 内部碎片
    - 分段: 段表 外部碎片
    - 段页式: 将进程地址空间划分若干个逻辑段，每一段划分为若干个大小固定的页 既有分段的共享与保护，也有分页系统的虚拟内存功能
    - 缺页率 缺页中断(属于异常)
    - 页置换算法: 先进先出页置换算法(FIFO) 二次机会置换算法 时钟置换算法 最佳置换算法(ORT) 最近最久未使用置换算法(LRU) 最近未使用置换算法(NRU)
    - 页分配策略: 固定分配局部置换 可变分配全局置换 可变分配局部置换
    - 分段与分页区别: 地址空间的维度 程序空间的透明性 大小是否可以改变 各自出现的原因 信息共享 内存碎片
    - 颠簸: 页置换算法 降低多道进程数量 杀死进程 增加进程内存
- 设备管理
    - 磁盘结构: 盘面 磁道 扇区 磁头 制动悬臂 主轴
    - 读写一个磁盘块的时间: 寻道时间 旋转时间 实际的数据传输时间
    - 磁盘调度算法: 先到先服务调度(FIFS) 最短寻道时间优先调度(SSTF) 电梯算法(SCAN) C-SCAN LOOK C-LOOK
- 链接
    - 编译系统: 预编译阶段 编译阶段 汇编阶段 链接阶段
    - 静态链接: 符号解析 重定向
    - 目标文件: 可执行目标文件 可重定向目标文件 共享目标文件
    - 动态链接: 
- 其他
    1. **字节序**: 
        1. **大端字节序**: 高位字节在前，低位字节在后，这是人类读写数值的方法。如 0x1234567 表示为 01 23 45 67。
        2. **小端字节序**: 低位字节在前，高位字节在后，即以0x1122形式储存。如 0x1234567 表示为 67 45 23 01。
        3. **为什么会有小端字节序**？答案是，计算机电路先处理低位字节，效率比较高，因为计算都是从低位开始的。所以，**计算机的内部处理都是小端字节序**。但是，人类还是习惯读写大端字节序。所以，**除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。**
        4. 计算机处理字节序的时候，不知道什么是高位字节，什么是低位字节。它只知道按顺序读取字节，先读第一个字节，再读第二个字节。如果是大端字节序，先读到的就是高位字节，后读到的就是低位字节。小端字节序正好相反。
        5. 字节序的处理，就是一句话："只有读取的时候，才必须区分字节序，其他情况都不用考虑。"
    2. **float**: 1个符号位 8个指数位(**指数位是8位，但是全0跟全1都是不允许的所以取值范围**) 23个数据位，如3.5 ==> 0b11.1 ==> 0b1.11e1 ==> (1 + 127)的指数位 0 10000000 11000000000000000000000 ==> 0100 0000 0110 0000 0000 0000 0000 0000 => 4 0 6 0 0 0 0 0 ==> 小端存储: 0x 00 00 60 40 ， 大端存储 0x 40 60 00 00。
        1. **有效位数为7**: 单精度数的尾数用23位存储，加上默认的小数点前的1位1，有24位，可以表示(2^25-1)的数字，所以有效数为7位，因为10^8>(2^25-1)>10^7。
        2. **取值范围**: 负数取值范围为 -3.4028235E+38 到 -1.401298E-45，正数取值范围为 1.401298E-45 到 3.4028235E+38。
            1. 因为指数位范围-126~127，而**2^128=3.40e+38**(之所以这样算是因为那24个其他数位如果全部取1的话也很接近2^128了)
            2. **2^(-126-23)=1.40e-45**。
        3. 指数位全为0的情况指数E等于1e-127，有效数字M不再加上第一位的1，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字。
        4. 指数位全为1的情况，这时，如果有效数字M全为0，表示±无穷大（正负取决于符号位s）；如果有效数字M不全为0，表示这个数不是一个数(NaN)。
    3. **double**: 1符号位 11指数位(-1023~1024) 52数据位。
        1. **有效位数为16**: 双精度数有效数位为16位。
        2. **取值范围**: 负值取值范围 -1.79769313486231570E+308 到 -4.94065645841246544E-324，正值取值范围为 4.94065645841246544E-324 到 1.79769313486231570E+308。
            1. **2^1024=1.79769313486231570E+308**
            2. **2^(-1023-52)=4.94065645841246544E-324**
    4. java的整型数值都是有符号的，规定数据的二进制形式第一位为符号位。0为正，1为负。所以，十进制3的**原码**为00000000 00000000 00000000 00000011，十进制-3的原码为10000000 00000000 00000000 00000011。
    5. **反码**是原码符号位不变，其它位按位取反。十进制3的反码为01111111 11111111 11111111 11111100，十进制-3的反码为11111111 11111111 11111111 11111100。
    6. **补码**，正数的补码与原码相同，负数的补码是反码加1。十进制3的补码为00000000 00000000 00000000 00000011，十进制-3的补码为11111111 11111111 11111111 11111111 11111101。
    7. 二进制的数据已经可以运算，为什么还要用补码？这是为了方便计算。有没有发现，-3的补码与3的原码之和刚好为0。这表明负数的补码是正数原码的相反数。采用补码进行计算，简化了减法运算，把减法转化成了加法运算。规律：**负数补码的补码等于原码。**
    8. **网络字节序**: UDP/TCP/IP协议规定:把接收到的第一个字节当作高位字节看待，这就要求发送端发送的第一个字节是高位字节；而在发送端发送数据时，发送的第一个字节是该数值在内存中的起始地址处对应的那个字节，也就是说，该数值在内存中的起始地址处对应的那个字节就是要发送的第一个高位字节(即：高位字节存放在低地址处)；由此可见，多字节数值在发送之前，在内存中因该是以大端法存放的；所以说，**网络字节序是大端字节序**；比如，我们经过网络发送整型数值0x12345678时，在80X86平台中，它是以小端发存放的，在发送之前需要使用系统提供的字节序转换函数htonl()将其转换成大端法存放的数值。
    9. **常见CPU的字节序**: Big Endian : PowerPC、IBM、Sun; Little Endian : x86、DEC; ARM既可以工作在大端模式，也可以工作在小端模式。
    10. **比特序**: 比特序就是一个字节中的bit顺序问题。一般情况下系统的比特序和字节序是保持一致的。对应分为以下情况: 
        1. LSB 0 位序：字节的第0位存放数据的least significant bit，即我们的数据的最低位存放在字节的第0位。（对应小端字节序） 
        2. MSB 0 位序：节的第0位存放数据的most significant bit，即我们的数据的最高位存放在字节的第0位。（对应大端字节序） 
        3. 字节序与bit序的转换: 字节序转换函数ntohl(s)、htonl(s) 。 从htonl、ntohl的源码来看确实只进行了字节序的转换并没有进行比特序的转换，这是因为系统帮我们自动做了转换。比特的发送、接收顺序是指一个字节中的bit在网络电缆中是如何发送、接收的。在以太网(Ethernet)中，是从最低有效比特位到最高有效比特位的发送顺序，也就是最低有效比特位首先发送。即**以太网是以小端的顺序发送比特位的**。
        4. 比特的发送、接收顺序对CPU、软件都是不可见的，（对诸如PHY的serdes(串行器和解串器)以及网卡写总线的硬件设计是非常重要的）因为我们的网卡会给我们处理这种转换，在发送的时候按照小端序发送比特位，在接收的时候**网卡会把接收到的比特序转换成主机的比特序**。

[TOC]

### 操作系统概述

#### 基本特征

1. **并发**: 指宏观上在一段时间内能同时运行多个程序，而**并行**则指同一时刻能运行多个指令。并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。
    操作系统通过引入进程和线程，使得程序能够并发运行。
2. **共享**: 指系统中的资源可以被多个并发进程共同使用。有两种共享方式: **互斥共享和同时共享**。互斥共享的资源称为临界资源，例如打印机等，
    在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。
3. **虚拟**: 把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术: **时分复用技术和空分复用技术**。多个进程能在同一个处理器上并发执行使用了时分复用技术，
    让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。
    地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页从硬盘中置换到内存中。
4. **异步**: 指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

- **同步**方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。
- **异步**方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而异步方法通常会在另外一个线程中地执行着。整个过程，不会阻碍调用者的工作。

#### 基本功能

1. **进程管理**: 进程控制、进程同步、进程通信、死锁处理、处理机调度等。
2. **内存管理**: 内存分配、地址映射、内存保护与共享、虚拟内存等。
3. **文件管理**: 文件存储空间的管理、目录管理、文件读写管理和保护等。
4. **设备管理**: 完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

#### 系统调用

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。<br>
<!-- ![系统调用](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/tGPV0.png) -->
<div align="center><img alt="系统调用" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/tGPV0.png"/></div>

- **内核**从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境。
- **用户态**即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等。为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口: 即系统调用。
- **用户态和内核态的切换**: 当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。
    主要有三种方式: 
    - **系统调用**: 是操作系统的最小功能单位。是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。
    - **异常**: 当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如**缺页异常**。
    - **外围设备的中断**: 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，
        如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。
- **shell**是一个特殊的应用程序，俗称命令行，本质上是一个命令解释器，它下通系统调用，上通各种应用，通常充当着一种“胶水”的角色，来连接各个小功能程序，
    让不同程序能够以一个清晰的接口协同工作，从而增强各个程序的功能。同时，shell是可编程的，它可以执行符合shell语法的文本，这样的文本称为shell脚本，
    通常短短的几行shell脚本就可以实现一个非常大的功能，原因就是这些shell语句通常都对系统调用做了一层封装。为了方便用户和系统交互，一般，一个shell对应一个终端，
    终端是一个硬件设备，呈现给用户的是一个图形化窗口。我们可以通过这个窗口输入或者输出文本。这个文本直接传递给shell进行分析解释，然后执行。
- **Linux的系统调用主要有以下这些**: 
    Task | Commands
    :- |:-
    进程控制 | fork(); exit(); wait();
    进程通信 | pipe(); shmget(); mmap();
    文件操作 | open(); read(); write();
    设备操作 | ioctl(); read(); write();
    信息维护 | getpid(); alarm(); sleep();
    安全 | chmod(); umask(); chown();

#### 宏内核与微内核

- **宏内核(macrokernel)**: 将操作系统功能作为一个紧密结合的整体放到内核。由于各模块共享信息，因此有很高的性能。缺点是稳定性差，开发过程中的bug经常会导致整个系统挂掉。
- **微内核(microkernel)**: 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立，非常稳定。
    在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。因为需要频繁地在用户态和核心态之间进行切换，
    所以会有一定的性能损失。<br>
    <!-- ![微内核](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/2_14_microkernelArchitecture.jpg) -->
    <div align="center"><img alt="微内核" src="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/2_14_microkernelArchitecture.jpg"/></div>
- 单内核: 也称为宏内核。将内核从整体上作为一个大过程实现，并同时运行在一个单独的地址空间。所有的内核服务都在一个地址空间运行，相互之间直接调用函数，简单高效。<br>
    微内核: 功能被划分成独立的过程，过程间通过IPC进行通信。模块化程度高，一个服务失效不会影响另外一个服务。<br>
    **Linux内核**是一个单内核，同时又吸收了微内核的优点: 模块化设计，支持**动态装载内核模块**。Linux还避免了微内核设计上的缺陷，让一切都运行在内核态，直接调用函数，
    无需消息传递。

#### 中断分类

1. **外中断**: 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。
2. **异常**: 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。
3. **陷入**: 在用户程序中使用系统调用。

### 进程管理

#### 进程与线程

1. **进程是资源分配的基本单位**。进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。
    下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。<br>
    <!-- ![进程](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/a6ac2b08-3861-4e85-baa8-382287bfee9f.png) -->
    <div align="center"><img alt="进程" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/a6ac2b08-3861-4e85-baa8-382287bfee9f.png"/></div>

2. **线程是独立调度的基本单位**。一个进程中可以有多个线程，它们共享进程资源。QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，
    线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。<br>
    <!-- ![线程](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/3cd630ea-017c-488d-ad1d-732b4efeddf5.png) -->
    <div align="center"><img alt="线程" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/3cd630ea-017c-488d-ad1d-732b4efeddf5.png"/></div>

3. 区别: 
    1. 拥有资源: 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
    2. 调度: 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
    3. 系统开销: 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。
        类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
    4. 通信方面: 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

#### 进程状态的切换

将CPU切换到另一个进程需要保存当前进程的状态并恢复另一个进程的状态，这一任务称为**上下文切换(context switch)**，即进程间切换。

<!-- ![进程切换](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/ProcessState.png) -->
<div align="center"><img alt="进程切换" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/ProcessState.png"/></div>

- 就绪状态(ready): 等待被调度
- 运行状态(running)
- 阻塞状态(waiting): 等待资源

应该注意以下内容: 

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，
    在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

#### 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

1. **批处理系统**: 批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间(从提交到终止的时间)。
    1. **先来先服务** first-come first-serverd(FCFS): 按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，
        而长作业又需要执行很长时间，造成了短作业等待时间过长。
    2. **短作业优先** shortest job first(SJF): 按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，
        那么长作业永远得不到调度。
    3. **最短剩余时间优先** shortest remaining time next(SRTN): 按估计剩余时间最短的顺序进行调度。
2. **交互式系统**: 交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
    1. **时间片轮转**(ound-robin, RR): 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，
        由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。时间片轮转算法的效率和时间片的大小有很大关系: 
        因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。
    2. **优先级调度**: 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
    3. **多级反馈队列**: 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，
        每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，
        最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。
3. **实时系统**: 实时系统要求一个请求在一个确定时间内得到响应。分为**硬实时和软实时**，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

#### 进程同步

1. **临界区**: 对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。
    ```
    // entry section
    // critical section;
    // exit section
    ```

2. **同步与互斥**
    - 同步: 多个进程按一定顺序执行；
    - 互斥: 多个进程在同一时刻只有一个进程能进入临界区。

    一组并发进程互斥执行时必须满足如下准则: 

    - **平等竞争**: 不能假设各并发进程的相对执行速度。即各并发进程享有平等地、独立地竞争共有资源的权利，且在不采取任何措施的条件下，在临界区内任意指令结束时，
        其他并发进程可以进入临界区。
    - **不可独占**: 并发进程中的某个进程不在临界区时，它不能阻止其他进程进入临界区。
    - **互斥使用**: 并发进程中的若干个进程申请进入临界区时，只能允许一个进程进入。
    - **有限等待**: 并发进程中的某个进程从申请进入临界区时开始，应在有限时间内得以进入临界区。

3. **信号量(Semaphore)**: 一个整型变量(表示资源数量)，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。
    - down: 信号量 -1 ，然后如果信号量大于等于 0，则继续执行，否则阻塞后进入与该信号相对应的队列中，然后转进程调度。
    - up : 对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。
    
    down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。<br>
    如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量(Mutex) ，0 表示临界区已经加锁，1 表示临界区解锁。

    ```cpp
    typedef int semaphore;
    semaphore mutex = 1;
    void P1() {
        down(&mutex);
        // 临界区
        up(&mutex);
    }
    void P2() {
        down(&mutex);
        // 临界区
        up(&mutex);
    }
    ```

    **使用信号量实现生产者-消费者问题**<br>
    问题描述: 使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。因为缓冲区属于临界资源，
    因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，
    这里需要使用两个信号量: empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，
    生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。<br>
    注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况: 
    生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，
    消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

    ```cpp
    #define N 100
    typedef int semaphore;
    semaphore mutex = 1;
    semaphore empty = N;
    semaphore full = 0;
    void producer() {
        while(TRUE) {
            int item = produce_item();
            down(&empty);
            down(&mutex);
            insert_item(item);
            up(&mutex);
            up(&full);
        }
    }
    void consumer() {
        while(TRUE) {
            down(&full);
            down(&mutex);
            int item = remove_item();
            consume_item(item);
            up(&mutex);
            up(&empty);
        }
    }
    ```

4. **互斥的加锁实现**: 对临界区加锁以实现互斥。当某个进程进入临界区后，它将锁上临界区，直到它退出临界区为止。并发进程在申请进入临界区时，首先测试该临界区是否上锁。<br>
    加锁实现中的lock(key[S])和unlock(key[S])均为原子操作。有一点需要注意的是: 在系统实现时锁定位key[S]总是设置在公有资源所对应的数据结构中的。<br>
    加锁实现的**缺点**: 

    - 循环测试锁定位将损耗较多的CPU计算时间。
    - 另外使用加锁法实现进程间互斥时，还将导致在某些情况下出现不公平的情况。例如两个进程都如下时，就有可能出现其中一个进程的执行，导致另一个进程长期得不到处理机资源，
        而处于**永久饥饿状态(starvation)**。

        ```cpp
        A:
        lock(key[S]);
        access(S);
        unlock(key[S]);
        goto A;
        ```
    那么是否有办法解决这个问题呢？当然，很明显，办法是有的，我们可以为临界区设置一个管理员，由这个管理员来管理相应临界区的公有资源，它代表可用资源的实体，这个管理员就是信号量。

5. **管程**: 使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。<br>
    c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

    ```sql
    monitor ProducerConsumer
        integer i;
        condition c;

        procedure insert();
        begin
            // ...
        end;

        procedure remove();
        begin
            // ...
        end;
    end monitor;
    ```

    管程有一个重要特性: 在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否者其它进程永远不能使用管程。<br>
    管程引入了 **条件变量** 以及相关的操作: **wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。
    signal() 操作用于唤醒被阻塞的进程。**使用管程实现生产者-消费者问题**

    ```sql
    // 管程
    monitor ProducerConsumer
        condition full, empty;
        integer count := 0;
        condition c;
        procedure insert(item: integer);
        begin
            if count = N then wait(full);
            insert_item(item);
            count := count + 1;
            if count = 1 then signal(empty);
        end;
        function remove: integer;
        begin
            if count = 0 then wait(empty);
            remove = remove_item;
            count := count - 1;
            if count = N -1 then signal(full);
        end;
    end monitor;
    // 生产者客户端
    procedure producer
    begin
        while true do
        begin
            item = produce_item;
            ProducerConsumer.insert(item);
        end
    end;
    // 消费者客户端
    procedure consumer
    begin
        while true do
        begin
            item = ProducerConsumer.remove;
            consume_item(item);
        end
    end;
    ```

#### 经典同步问题

1. ***读者-写者问题***

    允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，
    一个互斥量 data_mutex 用于对读写的数据加锁。
    ```c
    typedef int semaphore;
    semaphore count_mutex = 1;
    semaphore data_mutex = 1;
    int count = 0;
    void reader() {
        while(TRUE) {
            down(&count_mutex);
            count++;
            if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
            up(&count_mutex);
            read();
            down(&count_mutex);
            count--;
            if(count == 0) up(&data_mutex);
            up(&count_mutex);
        }
    }

    void writer() {
        while(TRUE) {
            down(&data_mutex);
            write();
            up(&data_mutex);
        }
    }
    ```

    ...

2. ***哲学家进餐问题***

    五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动: 吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。<br>
    为了防止死锁的发生，可以设置两个条件: ①必须同时拿起左右两根筷子；②只有在两个邻居都没有进餐的情况下才允许进餐。
    ```c
    #define N 5
    #define LEFT (i + N - 1) % N // 左邻居
    #define RIGHT (i + 1) % N    // 右邻居
    #define THINKING 0
    #define HUNGRY   1
    #define EATING   2
    typedef int semaphore;
    int state[N];                // 跟踪每个哲学家的状态
    semaphore mutex = 1;         // 临界区的互斥
    semaphore s[N];              // 每个哲学家一个信号量

    void philosopher(int i) {
        while(TRUE) {
            think();
            take_two(i);
            eat();
            put_two(i);
        }
    }

    void take_two(int i) {
        down(&mutex);
        state[i] = HUNGRY;
        test(i);
        up(&mutex);
        down(&s[i]);
    }

    void put_two(i) {
        down(&mutex);
        state[i] = THINKING;
        test(LEFT);
        test(RIGHT);
        up(&mutex);
    }

    void test(i) {         // 尝试拿起两把筷子
        if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
            state[i] = EATING;
            up(&s[i]);
        }
    }
    ```

***某些概念***

IO操作主要经过以下流程: 用户线程调用 -> 内核线程调用 -> 磁盘 -> 内核缓冲区 -> 用户缓冲区。即数据的操作分为两个阶段: 磁盘->内核缓冲区; 内核缓冲区->用户缓冲区

首先我们要明确**阻塞与非阻塞发生在第一阶段**，关注的是程序在等待调用的结果时状态(数据准备好了吗)，如果一直等待着结果出来，不去干其他事，这就是**阻塞**；<br>
如果调用后立刻返回一个状态，如果没有准备好就挂起，干其他事去，之后再来询问，如此循环往复直到获得结果，这就是**非阻塞**。<br>
**同步与异步发生在两个阶段**，关注的是消息的通信机制，同步就是在结果没有出来前，调用时不会返回的，一旦返回就得到返回值，也就是说是调用者自己等待调用的结果；
异步则是调用发出后，直接返回没有等待结果，而是被调用者来通知调用者处理完成了。<br>
**同步I/O操作**: 导致请求进程阻塞，直达I/O操作完成；<br>
**异步I/O操作**: 不导致请求进程阻塞。<br>

#### 进程通信

进程同步与进程通信很容易混淆，它们的区别在于: 

- 进程同步: 控制多个进程按一定顺序执行；
- 进程通信: 进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

1. 管道: 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。具有以下限制: 只支持半双工通信(单向交替传输)；只能在父子进程中使用。
    ```c
    #include <unistd.h>
    int pipe(int fd[2]);
    ```

    <!-- ![管道](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/53cd9ade-b0a6-4399-b4de-7f1fbd06cdfb.png) -->
    <div align="center"><img alt="管道" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/53cd9ade-b0a6-4399-b4de-7f1fbd06cdfb.png"/></div>

2. FIFO: 也称为命名管道，去除了管道只能在父子进程中使用的限制。
    ```c
    #include <sys/stat.h>
    int mkfifo(const char *path, mode_t mode);
    int mkfifoat(int fd, const char *path, mode_t mode);
    ```

    FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。<br>
    <!-- ![FIFO](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/2ac50b81-d92a-4401-b9ec-f2113ecc3076.png) -->
    <div align="center"><img alt="FIFO" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/2ac50b81-d92a-4401-b9ec-f2113ecc3076.png"/></div>

3. 消息队列: 相比于 FIFO，消息队列具有以下优点: 
    - 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
    - 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
    - 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

4. 信号量: 是一个计数器，用于为多个进程提供对共享数据对象的访问。

5. 共享存储: 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。需要使用信号量用来同步对共享存储的访问。
    多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用使用内存的匿名段。

6. 套接字: 与其它通信机制不同的是，它可用于不同机器间的进程通信。

### 死锁

#### 必要条件

- **互斥**: 每个资源要么已经分配给了一个进程，要么就是可用的。
- **占有和等待**: 已经得到了某个资源的进程可以再请求新的资源。
- **不可抢占**: 已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- **环路等待**: 有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

#### 处理方法

主要有以下四种方法: 

- **鸵鸟策略**
- **死锁检测与死锁恢复**
- **死锁预防**
- **死锁避免**

#### 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，
或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

#### 死锁检测与死锁恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1. **每种类型一个资源的死锁检测**: 下图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。<br>
    图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。<br>每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，
    对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。<br>
    <!-- ![死锁检测一](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/b1fa0453-a4b0-4eae-a352-48acca8fff74.png) -->
    <div align="center"><img alt="死锁检测一" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/b1fa0453-a4b0-4eae-a352-48acca8fff74.png"/></div>

2. **每种类型多个资源的死锁检测**: 下图中，有三个进程四个资源，每个数据代表的含义如下: 

    - E 向量: 资源总量
    - A 向量: 资源剩余量
    - C 矩阵: 每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
    - R 矩阵: 每个进程请求的资源数量

    进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，
    A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。<br>算法总结如下: 每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，
    任何没有被标记的进程都是死锁进程。

    1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
    2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
    3. 如果没有这样一个进程，算法终止。

    <!-- ![死锁检测二](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png) -->
    <div align="center"><img alt="死锁检测二" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png"/></div>

3. **死锁恢复**:
    - 利用**抢占**恢复
    - 利用**回滚**恢复
    - 通过**杀死进程**恢复

#### 死锁预防

1. **破坏互斥条件**: 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。
2. **破坏占有和等待条件**: 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。
3. **破坏不可抢占条件**
4. **破坏环路等待**: 给资源统一编号，进程只能按编号顺序来请求资源。

#### 死锁避免

1. **安全状态**: 如下图，图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。
    从图 a 开始出发，先让 B 拥有所需的所有资源(图 b)，运行结束后释放 B，此时 Free 变为 5(图 c)；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，
    因此可以称图 a 所示的状态时安全的。<br>
    定义: 如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。<br>
    安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的**银行家算法**与**死锁检测算法**非常*类似*，可以结合着做参考对比。<br>
    <!-- ![安全状态](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/ed523051-608f-4c3f-b343-383e2d194470.png) -->
    <div align="center"><img alt="安全状态" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/ed523051-608f-4c3f-b343-383e2d194470.png"/></div>

2. **单个资源的银行家算法**: 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。
    下图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。<br>
    <!-- ![银行家算法一](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/d160ec2e-cfe2-4640-bda7-62f53e58b8c0.png) -->
    <div align="center"><img alt="银行家算法一" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/d160ec2e-cfe2-4640-bda7-62f53e58b8c0.png"/></div>

3. **多个资源的银行家算法**: 下图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示: 
    总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。<br>
    检查一个状态是否安全的算法如下: 

    - 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
    - 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
    - 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

    如果一个状态不是安全的，需要拒绝进入这个状态。

### 内存管理

#### 虚拟内存

虚拟内存的**目的**是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。<br>
为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，
但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。<br>
从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。
例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。<br>
<!-- ![虚拟内存](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/7b281b1e-0595-402b-ae35-8c91084c33c1.png) -->
<div align="center"><img alt="虚拟内存" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/7b281b1e-0595-402b-ae35-8c91084c33c1.png"/></div>

**局部性原理**。局部性原理体现在两个方面:

- **时间的局部性**，如果程序中某条指令(数据访问)一旦执行，不久以后可能会再次执行(访问)，这主要由于程序中存在大量的循环操作；
- **空间的局部性**，一旦程序访问了某个存储单元，在不久之后，其附近的存储单元可能也将被访问，这主要由于指令都属顺序存放，运行的，数据也一般以数组、表等形式存储。

虚拟内存技术就是运用的局部性原理，建立了内存—外存的两级存储器结构。在程序装入时，可以将一部分装入内存，其余部分在外存，在执行过程中，当访问的信息不在内存中时，
再把需要的调入内存，继续执行程序，同时把暂时不用的内容替换到外存中。

内存管理模式: 

- **分页**
- **分段**
- **段页式**

#### 分页系统地址映射

通过将主存划分为大小相同且固定的块(较小)，作为主存的基本单位，每个进程也以块作为单位进行划分，进程在执行中，以块为单位逐个申请主存中的块空间的技术。
分页管理**不会产生外部碎片，但可能产生内部碎片，平均下来一个进程有半页的内部碎片。** 

- **页面**: 虚拟内存空间按照固定大小划分的页面称为页面
- **页框**: 内存中对应(页面)的块成为页框
- **页表**: 为了便于内存中找到进程的每个页面对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号。也就是页面与页框的对应关系表，页面由页表项组成。
    针对大内存，可以采用多级页表，获得较小页表的数量。
- **页表项**: 页表项主要由页号和物理内存的块号组成，它分页存储的地址结构页内偏移量共同组成物理地址。
- **快表(TLB)**: 运用高速缓冲存储器存放当前访问过若干页表项(大小不变)，加速地址变换的过程。不使用TLB时，每次取数据都需要两次访问内存，即查页表获得物理地址和取数据；
    使用了TLB只要访问一次内存和一次TLB。

内存管理单元(MMU)管理着地址空间和物理内存的转换，其中的页表(Page table)存储着页(程序地址空间)和页框(物理内存空间)的映射表。<br>
一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。<br>
下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址(0010 000000000100)，前 4 位是存储页面号 2，读取表项内容为(110 1)，
页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 (110 000000000100)。<br>

#### 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。
页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。
页面置换算法的主要目标是使页面置换频率最低(也可以说缺页率最低)。

1. **一般中断与缺页中断(属于异常)的区别**: 一般中断只需要保护现场然后就直接跳到需及时处理的地方。而缺页中断除了保护现场之外，还要判断内存中是否有足够的空间存储所需的页或段，然后再把所需页调进来再使用。
2. **常见页面置换算法**
    - *最佳置换算法*(OPT, Optimal replacement algorithm): 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。是一种理论上的算法，
        因为无法知道一个页面多长时间不再被访问。
    - *最近最久未使用置换算法*(LRU, Least Recently Used): 虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。
        为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
        因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。
    - *最近未使用*(NRU, Not Recently Used): 每个页面都有两个状态位: R与M，当页面被访问时设置页面的R=1，当页面被修改时设置M=1。其中R位会定时被清零。可以将页面分成以下四类: 
        - R=0，M=0
        - R=0，M=1
        - R=1，M=0
        - R=1，M=1

        当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。NRU 优先换出已经被修改的脏页面(R=0，M=1)，而不是被频繁使用的干净页面(R=1，M=0)。
    - *先进先出页面置换算法*(FIFO, First In First Out): 选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。
    - *二次机会算法*: FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改: 当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，
        检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。
    - *时钟置换算法*(CLOCK、NRU): 第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。
3. **页面分配策略**: 
    - *固定分配局部置换*: 为每个进程分配一定的数目的物理块，在整个运行期不变，发生缺页，则选择内存的页面置换需要的页面；
    - *可变分配全局置换*: 为每一个进程分配一定数目的物理块，操作系统自身保持一个空闲物理块队列，当发生缺页时，系统从空闲队列中取出一个物理块分配给进程；
    - *可变分配局部置换*: 为每一个进程分配一定数目的物理块，发生缺页时，只允许从该进程内存中选一页置换，如果进程频繁缺页，系统再为其分配若干个物理块，直至缺页率趋于适当水平，反之，则减少分配给该进程的物理块。

#### 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。<br>
下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。<br>
<!-- ![分页编译器示意图](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/22de0538-7c6e-4365-bd3b-8ce3c5900216.png) -->
<div align="center"><img alt="分页编译器表示意图" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/22de0538-7c6e-4365-bd3b-8ce3c5900216.png"/></div>

采用分页内存管理有一个不可避免的问题: 用户视角的内存和实际内存的分离。采用分段管理按照用户进程中的自然段划分逻辑空间更符合用户的实际需求，**分段要求段内连续，段外不要求连续**。

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。<br>
<!-- ![分段编译器表示意图](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png) -->
<div align="center"><img alt="分段编译器表示意图" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png"/></div>

**段表**: 每个进程都有一张逻辑空间与内存空间映射的段表，每一个段表项对应进程的一个段，段表项记录该段在内存中的起始位置的段的长度。**不会有内部碎片但是可能产生外部碎片**。

#### 段页式

分段存储可以反应程序逻辑结构并有利于段的共享，分页管理有利于提高内存利用率，结合两种管理，**将进程地址空间划分若干个逻辑段，每一段划分为若干个大小固定的页**。<br>
程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既**拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能**。<br>

#### 分页与分段的比较

1. 
    - **对程序员的透明性**: 分页透明，但是分段需要程序员显示划分每个段。
    - **地址空间的维度**: 分页是一维地址空间，分段是二维的。
    - **大小是否可以改变**: 页的大小不可变，段的大小可以动态改变。
    - **各自出现的原因**: 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。
2. 
    <!-- - **目的**: 分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息;
    - **大小**: 页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；
    - **地址空间不同**: 段向用户提供二维地址空间；页向用户提供的是一维地址空间； -->
    - **信息共享**: 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；
    - **内存碎片**: 页式存储管理的优点是没有外碎片(因为页的大小固定)，但会产生内碎片(一个页可能填充不满)；而段式管理的优点是没有内碎片(因为段大小可变，改变段大小来消除内碎片)。但段换入换出时，会产生外碎片(比如4k的段换5k的段，会产生1k的外碎片)。

#### 颠簸

- 颠簸: 频繁的页调度行为，不断产生缺页中断，导致整个系统的效率急剧下降
- 内存颠簸的解决策略包括: 
    - 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题；
    - 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量；
    - 否则，还剩下两个办法: 终止该进程或增加物理内存容量。

### 设备管理

#### 磁盘结构

- **盘面(Platter)**: 一个磁盘有多个盘面；
- **磁道(Track)**: 盘面上的圆形带状区域，一个盘面可以有多个磁道；
- **扇区(Track Sector)**: 磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- **磁头(Head)**: 与盘面非常接近，能够将盘面上的磁场转换为电信号(读)，或者将电信号转换为盘面的磁场(写)；
- **制动手臂(Actuator arm)**: 用于在磁道之间移动磁头；
- **主轴(Spindle)**: 使整个盘面转动。

![磁盘结构](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/014fbc4d-d873-4a12-b160-867ddaed9807.jpg)
<div align="center"><img alt="磁盘结构" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/014fbc4d-d873-4a12-b160-867ddaed9807.jpg"/></div>

#### 磁盘调度算法

读写一个磁盘块的时间的影响因素有: 

- **旋转时间**(主轴转动盘面，使得磁头移动到适当的扇区上)
- **寻道时间**(制动手臂移动，使得磁头移动到适当的磁道上)
- **实际的数据传输时间**

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

1. **先来先服务**(FCFS, First Come First Served): 按照磁盘请求的顺序进行调度。优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。
2. **最短寻道时间优先**(SSTF, Shortest Seek Time First): 优先调度与当前磁头所在磁道距离最近的磁道。虽然平均寻道时间比较低，但是不够公平。<br>
    如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。<br>
    <!-- ![SSTF](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/4e2485e4-34bd-4967-9f02-0c093b797aaa.png) -->
    <div align="center"><img alt="SSTF" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/4e2485e4-34bd-4967-9f02-0c093b797aaa.png"/></div>
3. **电梯算法**(SCAN): 电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。电梯算法(扫描算法)和电梯的运行过程类似，总是按一个方向来进行磁盘调度，
    直到该方向上没有未完成的磁盘请求，然后改变方向。因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。
    ![SCAN](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/271ce08f-c124-475f-b490-be44fedc6d2e.png)
    <div align="center"><img alt="SCAN" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/271ce08f-c124-475f-b490-be44fedc6d2e.png"/></div>

4. **C-SCAN调度**(circular SCAN, C-SCAN): 与 SCAN 一样， C-SCAN 将磁头从磁盘一端移到磁盘的另一端，随着移动不断地处理请求。不过，当磁头移到另一端时，它会马上返回到磁盘开始，
    返回时并不处理请求。
5. **LOOK调度**: 类似SCAN，磁头只移动到一个方向上最远的请求为止。
6. **C-LOOK调度**: 类似C-SCAN，磁头只移动到一个方向上最远的请求为止。

### 链接 

#### 编译系统

```c
#include <stdio.h>
int main() {
    printf("hello, world\n");
    return 0;
}
```

在 Unix 系统上，由编译器把源文件转换为目标文件: ``gcc -o hello hello.c``。这个过程大致如下: 
 
- **预处理阶段**: 处理以 # 开头的预处理命令；
- **编译阶段**: 翻译成汇编文件；
- **汇编阶段**: 将汇编文件翻译成可重定向目标文件；
- **链接阶段**: 将可重定向目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。

<!-- ![编译系统](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/b396d726-b75f-4a32-89a2-03a7b6e19f6f.jpg) -->
<div align="center"><img alt="编译系统" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/b396d726-b75f-4a32-89a2-03a7b6e19f6f.jpg"/></div>

#### 静态链接

静态链接器以一组可重定向目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务: 

- **符号解析**: 每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
- **重定位**: 链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

<!-- ![静态链接](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/47d98583-8bb0-45cc-812d-47eefa0a4a40.jpg) -->
<div align="center"><img alt="静态链接" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/47d98583-8bb0-45cc-812d-47eefa0a4a40.jpg"/></div>

#### 目标文件

- **可执行目标文件**: 可以直接在内存中执行；
- **可重定向目标文件**: 可与其它可重定向目标文件在链接阶段合并，创建一个可执行目标文件；
- **共享目标文件**: 这是一种特殊的可重定向目标文件，可以在运行时被动态加载进内存并链接；

#### 动态链接

静态库有以下两个问题: 

- 当静态库更新时那么整个程序都要重新进行链接；
- 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点: 

- 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
- 在内存中，一个共享库的 .text 节(已编译程序的机器代码)的一个副本可以被不同的正在运行的进程共享。

<!-- ![动态链接](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/76dc7769-1aac-4888-9bea-064f1caa8e77.jpg) -->
<div align="center"><img alt="动态链接" src="https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/76dc7769-1aac-4888-9bea-064f1caa8e77.jpg"/></div>

### 参考

[计算机操作系统](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/计算机操作系统.md)
[Operating System Notes](https://applied-programming.github.io/Operating-Systems-Notes/)
[Operating-System Structures](http://cse.csusb.edu/tongyu/courses/cs460/notes/process.php)
[Processes](http://cse.csusb.edu/tongyu/courses/cs460/notes/process.php)
[Inter Process Communication Presentation[1]](https://www.slideshare.net/rkolahalam/inter-process-communication-presentation1)
[Decoding UCS Invicta – Part 1](https://blogs.cisco.com/datacenter/decoding-ucs-invicta-part-1)
[I/O 阻塞与非阻塞，同步与异步](https://www.cnblogs.com/kiplove/p/6724431.html)

### end